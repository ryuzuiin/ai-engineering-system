# ğŸ“Œ torch.tensor() çš„æºç å…¥å£åˆ†æ

> æœ¬ç¬”è®°è®°å½•äº†æˆ‘å¯¹ PyTorch ä¸­ `torch.tensor()` æ„é€ å¼ é‡è¿‡ç¨‹çš„ç²¾è¯»è·¯å¾„ã€‚ç›®æ ‡æ˜¯ææ¸…æ¥š Python list æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥å˜æˆ Tensorï¼Œå¹¶æœ€ç»ˆåˆ†é…åˆ° CPU/GPU ä¸Šçš„å†…å­˜ä¸­çš„ã€‚

---

## ğŸšª å…¥å£å‡½æ•°

é¦–å…ˆï¼Œ`torch.tensor(data)` å®é™…ä¸Šè°ƒç”¨çš„æ˜¯ï¼š

```python
# torch/__init__.py
def tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False):
    return _tensor(data, dtype=dtype, device=device, requires_grad=requires_grad, pin_memory=pin_memory)

ğŸ§© _tensor() çš„å®ç°

ä½ç½®ï¼štorch/_utils.py

def _tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False):
    if isinstance(data, Tensor):
        if dtype is not None and data.dtype != dtype:
            data = data.to(dtype)
        if device is not None and data.device != device:
            data = data.to(device)
        return data.requires_grad_(requires_grad)
    return torch.as_tensor(data, dtype=dtype, device=device)
ğŸ“ æˆ‘çš„ç†è§£ï¼š
å¦‚æœ data å·²ç»æ˜¯ Tensorï¼Œå°±åªåš dtype/device çš„è½¬æ¢ã€‚
å¦åˆ™è¿›å…¥ä¸‹ä¸€å±‚ â€”â€” torch.as_tensor()ã€‚

ğŸ” torch.as_tensor()

ä½ç½®ï¼štorch/functional.py

def as_tensor(data, dtype=None, device=None):
    if isinstance(data, torch.Tensor):
        return data.to(dtype=dtype, device=device) if (dtype is not None or device is not None) else data
    return tensor(data, dtype=dtype, device=device)
æ³¨æ„è¿™é‡Œï¼š

è¿™ä¸ª tensor() å¹¶ä¸æ˜¯æœ€å¤–å±‚çš„ torch.tensor()ï¼Œè€Œæ˜¯ Python bindings åˆ° C++ çš„æ¥å£ã€‚
ğŸ§µ åˆ°è¿™é‡Œä¸ºæ­¢æˆ‘å­¦åˆ°äº†ï¼š

PyTorch å¯¹è¾“å…¥æ•°æ®åšäº†å¤šå±‚å°è£…ï¼Œç¡®ä¿æ•°æ®åœ¨ä¼ å…¥æ—¶è¢«å®‰å…¨è½¬æ¢æˆ tensorã€‚
çœŸæ­£çš„ Tensor æ„é€ å‡½æ•°åœ¨ C++ backend é‡Œï¼Œä¹‹åæˆ‘è¦è¿›ä¸€æ­¥ç ”ç©¶ torch/csrc/utils/tensor_new.cppï¼Œåˆ†æï¼š
Python list â†’ contiguous buffer çš„æ„å»ºè¿‡ç¨‹
Tensor çš„ shape æ¨æ–­é€»è¾‘
æ•°æ®ç±»å‹ï¼ˆdtypeï¼‰å’Œ device çš„é»˜è®¤å¤„ç†æµç¨‹
